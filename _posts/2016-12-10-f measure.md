---
layout: post
title: Imbalanced data issue
comments: true
---

# Imbalanced Issue
- 일상적으로 분류모델을 만들때 겪을수 있는 문제가 바로 Imbalanced data issue이다.
- 정상/비정상을 분류하는 모델을 만드는데 있어서 정상데이터가 비정상데이터에 비해 너무 많아서 생기는 문제이다.
	- 사실 일반적인 분류모델은 정상 비정상을 구분하려고 하는 목적인경우가 많다. 예를들면 제품이 불량인지 아닌지, 사기꾼일지 아닐지 예측하는 등 다양한 문제들이 정상비정상을 구분하기 위한 모델이다. 이들은 대부분 정상이 압도적으로 많고 비정상은 얼마없는 것이 특징이다.


- 예를들어 정상 99만개, 비정상 1만개의 데이터가 있다고 하자. 간단하게 분류모델을 만든다라고 생각하면, 모델의 성능을 확인하기 위해 전체 데이터를 7:3, 정도로 나누어 train, test데이터로 만들고, train데이터로 모델을 학습시킨후 test데이터를 얼마나 잘 맞추는지 확인할 것이다.
	- 그렇다면 test데이터를 잘맞추면 잘맞출 수록 모델의 성능이 좋다고 할 수 있다.
	- 하지만 모델이 모두다 정상으로 분류한다면? 그 모델의 성능은 얼마일까 대략, 99%의 정확도를 나타낼 것이다.
	- 이와 같은 문제가 바로 Imbalanced data issue이다.


그럼 어떻게 풀지???

### 1. Problem 1
- 우선 뭐가 잘못됬는지를 볼 수 있어야 한다.
- "모델의 성능"을 평가하는 방식을 달리하자

### Solution 1
- (흠 아직은 의문이 있음...)
- Precision / Recall / F measure 라는 성능 측정 방식을 도입해 보자

#### 1-1. Precision & Recall

#### 1-2. F measure

### 2. Problem 2
- 비정상 데이터가 부족하다. / 정상 비정상 간의 비율이 안맞다

### Soltion 2-1
- 데이터 수 자체를 늘리거나, 비율을 맞춰보자

### Soltion 2-2
- 약한쪽에 가중치를 부여해보자.

### 3. Problem 3
- 현재는 테스트데이터에서 정답률을 높이기 위해 거기에 너무 "집중"되어 있다.

### Solution 3
- 문제에 접근하는 방식을 달리해보자, 보통의 기계학습은 cost function을 정의하고 cost가 낮아지는 방향으로 학습한다. cost function이 현재 데이터가 비대칭 데이터라는 것을 알도록 새로운 형태로 구현해보자.

-
